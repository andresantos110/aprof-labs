{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-epochs EPOCHS] [-hidden_size HIDDEN_SIZE]\n",
      "                             [-layers LAYERS] [-learning_rate LEARNING_RATE]\n",
      "                             {perceptron,logistic_regression,mlp}\n",
      "ipykernel_launcher.py: error: the following arguments are required: model\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andre/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3441: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# Deep Learning Homework 1\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils\n",
    "\n",
    "\n",
    "def configure_seed(seed):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "class LinearModel(object):\n",
    "    def __init__(self, n_classes, n_features, **kwargs):\n",
    "        self.W = np.zeros((n_classes, n_features))\n",
    "\n",
    "    def update_weight(self, x_i, y_i, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def train_epoch(self, X, y, **kwargs):\n",
    "        for x_i, y_i in zip(X, y):\n",
    "            self.update_weight(x_i, y_i, **kwargs)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"X (n_examples x n_features)\"\"\"\n",
    "        scores = np.dot(self.W, X.T)  # (n_classes x n_examples)\n",
    "        predicted_labels = scores.argmax(axis=0)  # (n_examples)\n",
    "        return predicted_labels\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        \"\"\"\n",
    "        X (n_examples x n_features):\n",
    "        y (n_examples): gold labels\n",
    "        \"\"\"\n",
    "        y_hat = self.predict(X)\n",
    "        n_correct = (y == y_hat).sum()\n",
    "        n_possible = y.shape[0]\n",
    "        return n_correct / n_possible\n",
    "\n",
    "\n",
    "class Perceptron(LinearModel):\n",
    "    def update_weight(self, x_i, y_i, **kwargs):\n",
    "        \"\"\"\n",
    "        x_i (n_features): a single training example\n",
    "        y_i (scalar): the gold label for that example\n",
    "        other arguments are ignored\n",
    "        \"\"\"\n",
    "        # Q1.1a\n",
    "        y_hat = 1 if np.any(self.W.dot(x_i), 0) else -1\n",
    "        if y_hat != y_i:\n",
    "            self.W += y_i * x_i\n",
    "\n",
    "        # calcular y hat\n",
    "        # se diferente, mistake => atualizar w\n",
    "        # w += learning rate? (1) * y * x\n",
    "        #return w?\n",
    "\n",
    "        #raise NotImplementedError\n",
    "\n",
    "\n",
    "class LogisticRegression(LinearModel):\n",
    "    def update_weight(self, x_i, y_i, learning_rate=0.001):\n",
    "        \"\"\"\n",
    "        x_i (n_features): a single training example\n",
    "        y_i: the gold label for that example\n",
    "        learning_rate (float): keep it at the default value for your plots\n",
    "        \"\"\"\n",
    "        # Q1.1b\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class MLP(object):\n",
    "    # Q3.2b. This MLP skeleton code allows the MLP to be used in place of the\n",
    "    # linear models with no changes to the training loop or evaluation code\n",
    "    # in main().\n",
    "    def __init__(self, n_classes, n_features, hidden_size):\n",
    "        # Initialize an MLP with a single hidden layer.\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Compute the forward pass of the network. At prediction time, there is\n",
    "        # no need to save the values of hidden nodes, whereas this is required\n",
    "        # at training time.\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        \"\"\"\n",
    "        X (n_examples x n_features)\n",
    "        y (n_examples): gold labels\n",
    "        \"\"\"\n",
    "        # Identical to LinearModel.evaluate()\n",
    "        y_hat = self.predict(X)\n",
    "        n_correct = (y == y_hat).sum()\n",
    "        n_possible = y.shape[0]\n",
    "        return n_correct / n_possible\n",
    "\n",
    "    def train_epoch(self, X, y, learning_rate=0.001):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "def plot(epochs, valid_accs, test_accs):\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xticks(epochs)\n",
    "    plt.plot(epochs, valid_accs, label='validation')\n",
    "    plt.plot(epochs, test_accs, label='test')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('model',\n",
    "                        choices=['perceptron', 'logistic_regression', 'mlp'],\n",
    "                        help=\"Which model should the script run?\")\n",
    "    parser.add_argument('-epochs', default=20, type=int,\n",
    "                        help=\"\"\"Number of epochs to train for. You should not\n",
    "                        need to change this value for your plots.\"\"\")\n",
    "    parser.add_argument('-hidden_size', type=int, default=200,\n",
    "                        help=\"\"\"Number of units in hidden layers (needed only\n",
    "                        for MLP, not perceptron or logistic regression)\"\"\")\n",
    "    parser.add_argument('-layers', type=int, default=1,\n",
    "                        help=\"\"\"Number of hidden layers (needed only for MLP,\n",
    "                        not perceptron or logistic regression)\"\"\")\n",
    "    parser.add_argument('-learning_rate', type=float, default=0.001,\n",
    "                        help=\"\"\"Learning rate for parameter updates (needed for\n",
    "                        logistic regression and MLP, but not perceptron)\"\"\")\n",
    "    opt = parser.parse_args()\n",
    "\n",
    "    utils.configure_seed(seed=42)\n",
    "\n",
    "    add_bias = opt.model != \"mlp\"\n",
    "    data = utils.load_classification_data(bias=add_bias)\n",
    "    train_X, train_y = data[\"train\"]\n",
    "    dev_X, dev_y = data[\"dev\"]\n",
    "    test_X, test_y = data[\"test\"]\n",
    "\n",
    "    n_classes = np.unique(train_y).size  # 10\n",
    "    n_feats = train_X.shape[1]\n",
    "\n",
    "    # initialize the model\n",
    "    if opt.model == 'perceptron':\n",
    "        model = Perceptron(n_classes, n_feats)\n",
    "    elif opt.model == 'logistic_regression':\n",
    "        model = LogisticRegression(n_classes, n_feats)\n",
    "    else:\n",
    "        model = MLP(n_classes, n_feats, opt.hidden_size, opt.layers)\n",
    "    epochs = np.arange(1, opt.epochs + 1)\n",
    "    valid_accs = []\n",
    "    test_accs = []\n",
    "    for i in epochs:\n",
    "        print('Training epoch {}'.format(i))\n",
    "        train_order = np.random.permutation(train_X.shape[0])\n",
    "        train_X = train_X[train_order]\n",
    "        train_y = train_y[train_order]\n",
    "        model.train_epoch(\n",
    "            train_X,\n",
    "            train_y,\n",
    "            learning_rate=opt.learning_rate\n",
    "        )\n",
    "        valid_accs.append(model.evaluate(dev_X, dev_y))\n",
    "        test_accs.append(model.evaluate(test_X, test_y))\n",
    "\n",
    "    # plot\n",
    "    plot(epochs, valid_accs, test_accs)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
